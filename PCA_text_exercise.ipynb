{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ca084f-1207-4748-9f61-b16e12f6d730",
   "metadata": {},
   "source": [
    "# Linear Algebra Exercise: Principal Component Analysis\n",
    "\n",
    "## Background\n",
    "\n",
    "The **covariance matrix** **C** tells you how different variables vary together. Large diagonal elements mean high variance in that variable; large off-diagonal elements mean strong correlation between variables.\n",
    "\n",
    "The eigenvectors of **C** define new orthogonal axes (the \"principal components\"). The eigenvalues tell you how much variance lies along each axis. By projecting data onto just the top few eigenvectors, you can reduce dimensionality while keeping most of the information.\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "You're analyzing data from a system with 10 correlated sensors. The covariance matrix (already computed from centered data) is:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "# Covariance matrix from sensor measurements\n",
    "C = np.array([\n",
    "    [4.2, 2.1, 1.8, 0.9, 0.3, 0.2, 0.1, 0.0, -0.1, 0.0],\n",
    "    [2.1, 3.8, 1.6, 0.8, 0.4, 0.1, 0.2, 0.1, 0.0, -0.1],\n",
    "    [1.8, 1.6, 3.5, 1.2, 0.6, 0.3, 0.1, 0.0, 0.1, 0.0],\n",
    "    [0.9, 0.8, 1.2, 2.8, 0.9, 0.4, 0.2, 0.1, 0.0, 0.1],\n",
    "    [0.3, 0.4, 0.6, 0.9, 2.2, 0.7, 0.3, 0.2, 0.1, 0.0],\n",
    "    [0.2, 0.1, 0.3, 0.4, 0.7, 1.8, 0.5, 0.3, 0.2, 0.1],\n",
    "    [0.1, 0.2, 0.1, 0.2, 0.3, 0.5, 1.5, 0.4, 0.3, 0.2],\n",
    "    [0.0, 0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 1.2, 0.4, 0.3],\n",
    "    [-0.1, 0.0, 0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 1.0, 0.5],\n",
    "    [0.0, -0.1, 0.0, 0.1, 0.0, 0.1, 0.2, 0.3, 0.5, 0.9]\n",
    "])\n",
    "\n",
    "# Sample measurement in the original 10D space\n",
    "x = np.array([2.5, -1.3, 0.8, 1.2, -0.5, 0.3, -0.2, 0.4, 0.1, -0.3])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Principal Component Analysis\n",
    "\n",
    "### Task 1.1: Eigenvalue Decomposition\n",
    "\n",
    "Compute the eigenvalues and eigenvectors of the covariance matrix using. Store the eigenvalues in descending order and arrange the eigenvectors accordingly in a matrix **V**.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.2: Scree Plot\n",
    "\n",
    "Create a scree plot: plot the eigenvalues in descending order. \n",
    "\n",
    "Answer the following:\n",
    "- How many principal components would you keep to capture 90% of the variance? \n",
    "- How many for 95%?\n",
    "\n",
    "**Hint:** Total variance = sum of all eigenvalues. Cumulative variance fraction = (sum of first k eigenvalues) / (total variance)\n",
    "\n",
    "### Task 1.3: Projection onto PC Basis\n",
    "\n",
    "Project the measurement **x** onto the principal component basis.\n",
    "\n",
    "- Form a matrix **V** whose columns are the eigenvectors (sorted by eigenvalue, largest first)\n",
    "- Compute the projection: **z** = **V**ᵀ**x**\n",
    "\n",
    "The vector **z** contains the coordinates of your measurement in the PC basis.\n",
    "\n",
    "### Task 1.4: Dimensionality Reduction and Reconstruction\n",
    "\n",
    "Perform dimensionality reduction:\n",
    "\n",
    "1. Keep only the first 3 components of **z** (call this **z₃**)\n",
    "2. Reconstruct an approximation of the original measurement using: \n",
    "   $$\\mathbf{x}_{\\text{approx}} = \\mathbf{V}_3 \\mathbf{z}_3$$\n",
    "   where **V₃** is the matrix containing only the first 3 eigenvectors (first 3 columns of **V**)\n",
    "3. Compute the reconstruction error: ||**x** - **x_approx**|| (Euclidean norm, use `np.linalg.norm`)\n",
    "\n",
    "\n",
    "## Part 2: Linear Systems\n",
    "\n",
    "### Task 2.1: Sensor Calibration Problem\n",
    "\n",
    "Suppose you want to express a target measurement **b** as a linear combination of your sensor readings. You need to find coefficients **α** such that:\n",
    "\n",
    "$$\\mathbf{C} \\boldsymbol{\\alpha} = \\mathbf{b}$$\n",
    "\n",
    "where **b** is given by:\n",
    "```python\n",
    "b = np.array([3.0, 2.5, 2.0, 1.5, 1.0, 0.8, 0.6, 0.4, 0.3, 0.2])\n",
    "```\n",
    "\n",
    "**a)** Solve this linear system using `scipy.linalg.solve` to find **α**.\n",
    "\n",
    "**b)** Verify your solution by computing **C α** and comparing it to **b**.\n",
    "```python\n",
    "\n",
    "### Task 2.2: BONUS - Gauss Elimination (without pivoting)\n",
    "\n",
    "Implement your own Gauss elimination function (without pivoting) to solve the same system **C α = b**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
